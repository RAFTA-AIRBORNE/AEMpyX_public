{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e518f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b55676d",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "This script presents a work flow for ingesting AEM data for further\n",
    "preprocessing.\n",
    "@author: vrath nov 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d0e9e2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from sys import exit as error\n",
    "from time import process_time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import numpy\n",
    "\n",
    "\n",
    "AEMPYX_ROOT = os.environ[\"AEMPYX_ROOT\"]\n",
    "mypath = [AEMPYX_ROOT+\"/aempy/modules/\", AEMPYX_ROOT+\"/aempy/scripts/\"]\n",
    "for pth in mypath:\n",
    "    if pth not in sys.path:\n",
    "        sys.path.insert(0,pth)\n",
    "\n",
    "from version import versionstrg\n",
    "import util\n",
    "import aesys\n",
    "\n",
    "AEMPYX_DATA = os.environ[\"AEMPYX_DATA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf3ee14",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m version, _ \u001b[38;5;241m=\u001b[39m versionstrg()\n\u001b[0;32m----> 2\u001b[0m titstrng \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mprint_title(version\u001b[38;5;241m=\u001b[39mversion, fname\u001b[38;5;241m=\u001b[39m\u001b[38;5;18;43m__file__\u001b[39;49m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(titstrng\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m now \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "version, _ = versionstrg()\n",
    "titstrng = util.print_title(version=version, fname=__file__, out=False)\n",
    "print(titstrng+\"\\n\\n\")\n",
    "\n",
    "now = datetime.now()\n",
    "Header = titstrng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eafb29b",
   "metadata": {},
   "source": [
    "Now some parameters controlling the work flow need to be defined. \n",
    "\n",
    "\\textit{OutInfo = True} will activate the output of some intermediate information.\n",
    "This parameter, as well as most of the header, is common to all tutorial scripts.\n",
    "\\begin{description}\n",
    "\\item[OutInfo = True] \n",
    " will activate the output of some intermediate information.\n",
    "This parameter, as well as most of the header, is common to all tutorial scripts.\n",
    "\\item[FileList = \"search\"] will choose a search of files to be read based on a \n",
    "string search (including wildcards). This parameter, as well as most of the header, \n",
    "is common to all tutorial scripts.\n",
    "\\item[SearchStr = \".xyz\"] is only necessary when \"search\" is chosen.\n",
    "\\item[FileList = \"set\"] will require a list of files stored in the variable \n",
    "\\textit{DataSet}. \n",
    " \n",
    "\\end{description}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac188c8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "OutInfo = True\n",
    "\n",
    "FileList = \"search\"  \n",
    "SearchStr = \".xyz\"\n",
    "DataSet = []\n",
    "\n",
    "# FileList = \"set\"\n",
    "# DataSet = [\"File1\", \"File2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d70b808",
   "metadata": {},
   "source": [
    "The following parameter control the treatment and output of data. \n",
    "\\textit{CheckNaN = True} will look for invalid data (e.g., \"*\" when \n",
    "exported by Geosoft). \\textit{MergeOut = True} and \n",
    "\\textit{LinesOut = True} will activate the output of full data set and \n",
    "individual fligh tlines, respectively. The former is convenient for any \n",
    "task requiring spatial information. The minimum number of sites can be \n",
    "set, if individual flight lines are exported.  \n",
    "\n",
    "We suggest using the \".npz\" ouput format, as it  is the easiest and \n",
    "fastest to be read by any python software, an uses compression, leading \n",
    "to smaller file sizes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76b0c944",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "CheckNaN = True\n",
    "MergeOut = True   \n",
    "LinesOut = True  \n",
    "LinesMin = 30\n",
    "\n",
    "OutFileFmt = \".npz\" #\".asc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25bb867",
   "metadata": {},
   "source": [
    "The following two parameters allow to change the projections (now redundant, \n",
    "as this is already done in module \\textit{aesys.py}). GSI chose the ITM system \n",
    "(EPSG=2157), which is not known to many useful software, e.g., google earth. \n",
    "Within \\textit{AEMpyX}, the coordinates are in UTM (Zone 29N, EPSG==32629). Flight \n",
    "lines should also be stored in the same direction, setting \n",
    "\\textit{CorrectDirection=True}. This is convenient for practical reasons, as comparing plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a9dbe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "SetProj = False\n",
    "if SetProj:\n",
    "    ProjInp = \"\"\n",
    "    ProjOut = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c2cef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "TellusAng = 345.\n",
    "Spread = 5.\n",
    "CorrectDirection = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7779dc8",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "The following block defines the choice of date to be processed. Most often the \n",
    "choice is simply a rectangle, as demonstrated here. The original data files \n",
    "provided by GSI are too large to be stored with git, thus need to be downloaded from \n",
    "https://www.gsi.ie/en-ie/data-and-maps/Pages/Geophysics.aspx, and stored in a local \n",
    "directory of the user's choice (see below). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0191c8dd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We need define some necessary paramters controlling the reading of the original \n",
    "data, and the choice of an appropriate subset. In this case it is a rectangle \n",
    "covering the outcrops of black shapes in Co. Limerick, south of the Shannon estuary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b04cecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RectCorners = []\n",
    "PolyFiles = []\n",
    "DataSelect = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac3e49b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AEM system is aem05\n",
      "Forward model call: core1d.aemfwd1d_aem05(nlyr, m, alt)\n",
      "Data:[17, 6, 8, 3]\n"
     ]
    }
   ],
   "source": [
    "AEM_system = \"aem05\"\n",
    "_, NN, _, _, _, = aesys.get_system_params(AEM_system)\n",
    "nD = NN[0]\n",
    "\n",
    "AEMPYX_DATA = AEMPYX_ROOT+\"/work/\"\n",
    "DataSelect = \"Rectangle\"   # \"Polygon\", \"Intersection\", \"Union\"\n",
    "InDatDir = AEMPYX_DATA+\"/Limerick/\"\n",
    "OutDatDir = InDatDir+\"/raw/\"\n",
    "RectCorners = [486000., 5815000., 498000., 5828000.] \n",
    "InSurvey = \"A5\"\n",
    "OutStrng = InSurvey+\"_rect_shale\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53a77f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "After this, generally no code changes are necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96976e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from dir:  /home/vrath/AEMpyX//work//Limerick/\n",
      "Data written to dir: /home/vrath/AEMpyX//work//Limerick//raw/\n",
      "Flightline ID string: A5_rect_shale \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Data read from dir:  %s\" % InDatDir)\n",
    "print(\"Data written to dir: %s\" % OutDatDir)\n",
    "print(\"Flightline ID string: %s \\n\" % OutStrng)\n",
    "\n",
    "if \"search\" in FileList.lower():\n",
    "    DataSet = []\n",
    "\n",
    "    files = os.listdir(InDatDir)\n",
    "    for entry in files:\n",
    "        # print(entry)\n",
    "        if SearchStr in entry.lower():\n",
    "            DataSet.append(entry)\n",
    "\n",
    "DataSet = sorted(DataSet)\n",
    "ns = numpy.size(DataSet)\n",
    "\n",
    "if not os.path.isdir(OutDatDir):\n",
    "    print(\"File: %s does not exist, but will be created\" % OutDatDir)\n",
    "    os.mkdir(OutDatDir)\n",
    "\n",
    "\n",
    "dcount=0\n",
    "for dset in DataSet:\n",
    "    dcount=dcount+1\n",
    "    start = process_time()\n",
    "    file = InDatDir + dset\n",
    "    print(\"\\nRaw data read from: %s\" % file)\n",
    "    Datar = aesys.read_survey_data(DatFile=file, Survey=InSurvey, OutInfo=True)\n",
    "    if dcount == 1:\n",
    "        Data = Datar\n",
    "    else:\n",
    "        Data = numpy.vstack((Data, Datar))\n",
    "    print(\"Read time taken = \", process_time() - start, \"s \\n\")\n",
    "\n",
    "\n",
    "if SetProj:\n",
    "    start = process_time()\n",
    "    itm_e = Data[:,1]\n",
    "    itm_n = Data[:,2]\n",
    "    utm_e, utm_n = util.project_itm_to_utm(itm_e, itm_n) #, utm_zone=32629)\n",
    "    Data[:,1] = utm_e\n",
    "    Data[:,2] = utm_n\n",
    "    print(\"ITM Transformed to UTM\")\n",
    "    print(\"Projection time taken = \", process_time() - start, \"s \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ce543",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Data subsets based on rectangle, polygons or operators on polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28bd616a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m process_time()\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(numpy\u001b[38;5;241m.\u001b[39mshape(\u001b[43mData\u001b[49m)))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData select is \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mDataSelect\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrec\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m DataSelect\u001b[38;5;241m.\u001b[39mlower():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Data' is not defined"
     ]
    }
   ],
   "source": [
    "start = process_time()\n",
    "print(\"In: \"+str(numpy.shape(Data)))\n",
    "print(\"Data select is \"+DataSelect+\" \\n\")\n",
    "\n",
    "if \"rec\" in DataSelect.lower():\n",
    "    head = aesys.grow_header(Header, \"Subset: \" + str(RectCorners))\n",
    "    start = process_time()\n",
    "    Rect = util.extract_data_rect(Data, RectCorners)\n",
    "    if Rect.size != 0:\n",
    "        Data = Rect\n",
    "    else:\n",
    "        error(\"No data found in rectangle!\\n\")\n",
    "\n",
    "if \"pol\" in DataSelect:\n",
    "    head = aesys.grow_header(Header,\n",
    "            \" | Subset: \" + str(DataSet)+\": \"+PolyFiles[0])\n",
    "    Polygon = numpy.load(PolyFiles[0], allow_pickle=True)[\"Poly\"][0]\n",
    "    start = process_time()\n",
    "    Poly= util.extract_data_poly(Data, Polygon, method=\"shp\")\n",
    "    if Poly.size != 0:\n",
    "        Data = Poly\n",
    "    else:\n",
    "        error(\"No data found in polygon!\\n\")\n",
    "\n",
    "if (\"uni\" in DataSelect.lower()) or (\"int\" in DataSelect.lower()):\n",
    "    for polyfile in PolyFiles:\n",
    "        head = aesys.grow_header(Header,\n",
    "                \" | Subset: \"+DataSelect.lower()[0:3]+\": \"+polyfile)\n",
    "    Polygon1 = numpy.load(PolyFiles[0], allow_pickle=True)[\"Poly\"][0]\n",
    "    Polygon2 = numpy.load(PolyFiles[1], allow_pickle=True)[\"Poly\"][0]\n",
    "    start = process_time()\n",
    "    Polygon= util.modify_polygon([Polygon1, Polygon2], Operator=DataSelect)\n",
    "    Poly= util.extract_data_poly(Data, Polygon, method=\"shp\")\n",
    "    if Poly.size != 0:\n",
    "        Data = Poly\n",
    "    else:\n",
    "        error(\"No data found in polygons!\\n\")\n",
    "\n",
    "print(\"Data select time taken = \", process_time() - start, \"s \\n\")\n",
    "print(\"Out: \"+str(numpy.shape(Data)))\n",
    "\n",
    "if MergeOut:\n",
    "    head = aesys.grow_header(Header,\"All Lines\")\n",
    "    f = OutDatDir + OutStrng+\"_Full\"+OutFileFmt\n",
    "    aesys.write_aempy(File=f, Data=Data, System=AEM_system,\n",
    "                    Header=head, OutInfo=OutInfo)\n",
    "    print(\"All data written to File: \" + f )\n",
    "    print(\"Header written: \")\n",
    "    print(head)\n",
    "    print(\"time taken = \", process_time() - start, \"s \\n\")\n",
    "\n",
    "\n",
    "if LinesOut:\n",
    "    bad_files = 0\n",
    "    startlines = process_time()\n",
    "    Lines = sorted(numpy.unique(Data[:, 0]))\n",
    "    print(\">Flight lines in data set:\")\n",
    "    print(Lines)\n",
    "    for s in Lines:\n",
    "        tmp = Data[numpy.where(Data[:, 0] == s), :]\n",
    "        ns = numpy.shape(tmp)\n",
    "        tmp = numpy.reshape(tmp, (ns[1], ns[2]))\n",
    "        print(\"OutInfo: \"+str(numpy.shape(tmp)))\n",
    "\n",
    "        if numpy.size(tmp)<=nD*LinesMin:\n",
    "            print(\"Not enough data! Not written\")\n",
    "            continue\n",
    "\n",
    "        if CheckNaN:\n",
    "                nn = numpy.count_nonzero(numpy.isnan(tmp))\n",
    "                print (str(nn)+\" NaNs in Data Block\")\n",
    "                if nn >0:\n",
    "                    bad_files = bad_files+1\n",
    "                    print(\"Too many NaNs = \"+str(nn)+\" in block, not written\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "        if CorrectDirection:\n",
    "            AngLimits = [TellusAng-5., TellusAng+5. ]\n",
    "            nd =numpy.shape(tmp)[0]\n",
    "            spoint = [tmp[round(nd*0.3),1], tmp[round(nd*0.3),2]]\n",
    "            epoint = [tmp[round(nd*0.6),1], tmp[round(nd*0.6),2]]\n",
    "            ang, _ = util.get_direction_angle(spoint, epoint)\n",
    "            if (ang < TellusAng-Spread) or (ang > TellusAng+Spread):\n",
    "                tmp = numpy.flipud(tmp)\n",
    "                print(\" Angle = \"+str(round(ang,1))\n",
    "                    +\" not in interval \"\n",
    "                    +str(round(AngLimits[0],1))+\" - \"\n",
    "                    +str(round(AngLimits[1],1)))\n",
    "                print(\"Flightline direction has been reversed.\")\n",
    "                chdir = \", direction has been reversed\"\n",
    "            else:\n",
    "                print(\"Flightline direction is approx. 345 degrees\")\n",
    "                chdir = \"\"\n",
    "\n",
    "        head = aesys.grow_header(Header, \"Flightline \" + str(s))\n",
    "\n",
    "        f = OutDatDir + OutStrng + \"_FL\" + str(s).replace(\".\", \"-\")+OutFileFmt\n",
    "        aesys.write_aempy(File=f, Data=tmp, System=AEM_system,\n",
    "                        Header=head, OutInfo=OutInfo)\n",
    "        print(\"Flight line written to File: \" + f)\n",
    "        print(\"Header written: \")\n",
    "        print(head)\n",
    "        print(\"time taken = \", process_time() - start, \"s \\n\")\n",
    "\n",
    "    print(\"Flight line data, time taken = \",\n",
    "          process_time() - startlines, \"s \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b9238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "formats": "py:sphinx,ipynb",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
